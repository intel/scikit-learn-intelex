# ===============================================================================
# Copyright 2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ===============================================================================

import numbers
from numbers import Integral, Real

import numpy as np
from scipy import sparse as sp
from sklearn.base import BaseEstimator, ClusterMixin
from sklearn.metrics.pairwise import KERNEL_PARAMS, pairwise_kernels
from sklearn.utils.validation import check_array

from daal4py.sklearn._n_jobs_support import control_n_jobs
from daal4py.sklearn._utils import sklearn_check_version
from onedal.cluster import Louvain as onedal_Louvain
from onedal.utils.validation import _is_csr

from .._device_offload import dispatch
from .._utils import PatchingConditionsChain
from ..neighbors import NearestNeighbors

if sklearn_check_version("1.2"):
    from sklearn.utils._param_validation import Interval, StrOptions


@control_n_jobs(decorated_methods=["fit"])
class Louvain(ClusterMixin, BaseEstimator):
    """Cluster data using the Louvain network clustering algorithm.

    The Louvain algorithm is useful in circumstances where the affinity
    matrix of the data is sparse, providing operational runtime of
    approximately :math:`O(n * log(n))` for n samples. In cases where
    dense inputs are provided, a more-sparse representation is first
    generated.

    Output of the algorithm will yield a unique label generated by the
    greedy optimization of the graph modularity[1]_. The number of
    clusters is determined, not specified.

    When calling ``fit``, an affinity matrix is constructed using either
    a kernel function such the Gaussian (aka RBF) kernel with Euclidean
    distance ``d(X, X)``::

            np.exp(-gamma * d(X,X) ** 2)

    or a k-nearest neighbors connectivity matrix.

    Alternatively, a user-provided affinity matrix can be specified by
    setting ``affinity='precomputed'``.


    Parameters
    ----------
    resolution: float, default=1.0
        Modularity scaling parameter for determining cluster size [2]_

    tol: float, default=1e-4
        Tolerance for stopping criteria.

    max_iter : int, default=10
        Maximum number of iterations taken for Louvain algorithm convergence.

    gamma : float, default=1.0
        Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels.
        Ignored for ``affinity='nearest_neighbors'``, ``affinity='precomputed'``
        or ``affinity='precomputed_nearest_neighbors'``.

    affinity : str or callable, default='nearest_neighbors'
        How to construct the affinity matrix.
         - 'nearest_neighbors': construct the affinity matrix by computing a
           graph of nearest neighbors.
         - 'rbf': construct the affinity matrix using a radial basis function
           (RBF) kernel.
         - 'precomputed': interpret ``X`` as a precomputed affinity matrix,
           where larger values indicate greater similarity between instances.
         - 'precomputed_nearest_neighbors': interpret ``X`` as a sparse graph
           of precomputed distances, and construct a binary affinity matrix
           from the ``n_neighbors`` nearest neighbors of each instance.
         - one of the kernels supported by
           :func:`~sklearn.metrics.pairwise.pairwise_kernels`.

        Only kernels that produce similarity scores (non-negative values that
        increase with similarity) should be used. This property is not checked
        by the clustering algorithm.

    n_neighbors : int, default=10
        Number of neighbors to use when constructing the affinity matrix using
        the nearest neighbors method. Ignored for ``affinity='rbf'``.

    degree : float, default=3
        Degree of the polynomial kernel. Ignored by other kernels.

    coef0 : float, default=1
        Zero coefficient for polynomial and sigmoid kernels.
        Ignored by other kernels.

    kernel_params : dict of str to any, default=None
        Parameters (keyword arguments) and values for kernel passed as
        callable object. Ignored by other kernels.

    n_jobs : int, default=None
        The number of parallel jobs to run when `affinity='nearest_neighbors'`
        or `affinity='precomputed_nearest_neighbors'`. The neighbors search
        will be done in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.

    verbose : bool, default=False
        Verbosity mode.

    Attributes
    ----------
    affinity_matrix_ : array-like of shape (n_samples, n_samples)
        Affinity matrix used for clustering. Available only after calling
        ``fit``.

    community_count_ : int
        Number of communities generated during :term:`fit`.

    modularity_ : float
        The network modularity seen during :term:`fit`.

    labels_ : ndarray of shape (n_samples,)
        Labels of each point

    n_features_in_ : int
        Number of features seen during :term:`fit`.

        .. versionadded:: 0.24

    feature_names_in_ : ndarray of shape (`n_features_in_`,)
        Names of features seen during :term:`fit`. Defined only when `X`
        has feature names that are all strings.

        .. versionadded:: 1.0

    See Also
    --------
    sklearn.cluster.SpectralClustering : Clustering of a 
        normalized Laplacian projection.
    sklearn.cluster.KMeans : K-Means clustering.
    sklearn.cluster.DBSCAN : Density-Based Spatial Clustering of
        Applications with Noise.

    Notes
    -----
    A distance matrix for which 0 indicates identical elements and high values
    indicate very dissimilar elements can be transformed into an affinity /
    similarity matrix that is well-suited for the algorithm by
    applying the Gaussian (aka RBF, heat) kernel::

        np.exp(- dist_matrix ** 2 / (2. * delta ** 2))

    where ``delta`` is a free parameter representing the width of the Gaussian
    kernel.

    An alternative is to take a symmetric version of the k-nearest neighbors
    connectivity matrix of the points.

    References
    ----------
    .. [1] :doi:`Fast unfolding of communities in large networks, 2008
           Blondel, Vincent D; Guillaume, Jean-Loup; Lambiotte, Renaud; Lefebvre, Etienne
           <10.1088/1742-5468/2008/10/P10008>`

    .. [2] :doi:`Laplacian Dynamics and Multiscale Modular Structure in Networks, 2009
            Lambiotte, R; Delvenne J.C; Barahona, M
            <10.48550/arXiv.0812.1770>`

    Examples
    --------
    >>> from sklearnex.cluster import Louvain
    >>> import numpy as np
    >>> X = np.array([[1, 1], [2, 1], [1, 0],
    ...               [4, 7], [3, 5], [3, 6]])
    >>> clustering = Louvain(n_clusters=2, random_state=0).fit(X)
    >>> clustering.labels_
    array([1, 1, 1, 0, 0, 0])
    >>> clustering
    Louvain(n_clusters=2, random_state=0)
    """

    if sklearn_check_version("1.2"):
        _parameter_constraints: dict = {
            "resolution": [Interval(Real, 0.0, None, closed="left")],
            "tol": [Interval(Real, 0, None, closed="left")],
            "max_iter": [Interval(Integral, 0, None, closed="left")],
            "gamma": [Interval(Real, 0, None, closed="left")],
            "affinity": [
                callable,
                StrOptions(
                    set(KERNEL_PARAMS)
                    | {
                        "nearest_neighbors",
                        "precomputed",
                        "precomputed_nearest_neighbors",
                    }
                ),
            ],
            "n_neighbors": [Interval(Integral, 1, None, closed="left")],
            "degree": [Interval(Real, 0, None, closed="left")],
            "coef0": [Interval(Real, None, None, closed="neither")],
            "kernel_params": [dict, None],
            "n_jobs": [Integral, None],
            "verbose": ["verbose"],
        }

    def __init__(
        self,
        resolution=1.0,
        *,
        tol=1e-4,
        max_iter=10,
        gamma=1.0,
        affinity="nearest_neighbors",
        n_neighbors=10,
        degree=3,
        coef0=1,
        kernel_params=None,
        n_jobs=None,
        verbose=False,
    ):
        self.resolution = resolution
        self.tol = tol
        self.max_iter = max_iter
        self.gamma = gamma
        self.affinity = affinity
        self.n_neighbors = n_neighbors
        self.degree = degree
        self.coef0 = coef0
        self.kernel_params = kernel_params
        self.n_jobs = n_jobs
        self.verbose = verbose

    def fit(self, X, y=None):
        """Perform Louvain clustering from features, or affinity matrix.

        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features) or \
                (n_samples, n_samples)
            Training instances to cluster, similarities / affinities between
            instances if ``affinity='precomputed'``, or distances between
            instances if ``affinity='precomputed_nearest_neighbors``. If a
            sparse matrix is provided in a format other than ``csr_matrix``,
            it will be converted into a sparse ``csr_matrix``.

        y : array-like of shape (n_samples,), default=None
            Initial partitioning/clustering of the samples in X, default
            None will use no initial values.

        Returns
        -------
        self : object
            A fitted instance of the estimator.
        """
        return dispatch(
            self,
            "fit",
            {
                "onedal": self.__class__._onedal_fit,
                "sklearn": None,
            },
            X,
            y=y,
        )

    def _onedal_fit(self, X, y, queue=None):

        if sklearn_check_version("1.0"):
            X = self._validate_data(
                X,
                accept_sparse=["csr"],
                dtype=np.float64,
                ensure_min_samples=2,
            )
        else:
            X = check_array(
                X, accept_sparse=["csr"], dtype=np.float64, ensure_min_samples=2
            )

        if y is not None:
            pass


        if (
            self.affinity == "nearest_neighbors"
            or self.affinity == "precomputed_nearest_neighbors"
        ):
            estimator = NearestNeighbors(
                n_neighbors=self.n_neighbors,
                n_jobs=self.n_jobs,
                metric="precomputed" if "precomputed" in self.affinity else "minkowski",
            ).fit(X)
            connectivity = estimator.kneighbors_graph(mode="connectivity")
            self.affinity_matrix_ = 0.5 * (connectivity + connectivity.T)
        elif self.affinity == "precomputed":
            self.affinity_matrix_ = X
        else:
            params = self.kernel_params
            if params is None:
                params = {}
            if not callable(self.affinity):
                params["gamma"] = self.gamma
                params["degree"] = self.degree
                params["coef0"] = self.coef0
            self.affinity_matrix_ = pairwise_kernels(
                X, metric=self.affinity, filter_params=True, **params
            )
            # Implement truncation here

        if not _is_csr(self.affinity_matrix_):
            self.affinity_matrix_ = sp.csr_matrix(self.affinity_matrix_)

        self._onedal_estimator = self._onedal_factory()
        self._onedal_estimator.fit(self.affinity_matrix_, y=y, queue=queue)
        return self

    def _onedal_supported(self, method_name, *data):
        class_name = self.__class__.__name__
        patching_status = PatchingConditionsChain(
            f"sklearn.cluster.{class_name}.{method_name}"
        )

        if sklearn_check_version("1.2"):
            self._validate_params()
        return patching_status

    def _onedal_factory(self):
        onedal_params = {
            "resolution": self.resolution,
            "tol": self.tol,
            "max_iter": self.max_iter,
        }
        return onedal_Louvain(**onedal_params)

    _onedal_cpu_supported = _onedal_supported
    _onedal_gpu_supported = _onedal_supported

    @property
    def labels_(self):
        return self._onedal_estimator.labels_

    @labels_.setter
    def labels_(self, val):
        if not hasattr(self, "_onedal_estimator"):
            self._onedal_estimator = self._onedal_factory()

        self._onedal_estimator.labels_ = val

    @property
    def modularity_(self):
        return self._onedal_estimator.modularity_

    @modularity_.setter
    def modularity_(self, val):
        if not hasattr(self, "_onedal_estimator"):
            self._onedal_estimator = self._onedal_factory()

        self._onedal_estimator.modularity_ = val

    @property
    def community_count_(self):
        return self._onedal_estimator.community_count_

    @community_count_.setter
    def community_count_(self, val):
        if not hasattr(self, "_onedal_estimator"):
            self._onedal_estimator = self._onedal_factory()

        self._onedal_estimator.community_count__ = val
